{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de texto para NLP (parte 3)\n",
    "> \"o(^・x・^)o Embeddings pre-entrenados\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Matías Battocchia\n",
    "- categories: [nlp,pytorch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el artículo final de la serie preprocesamiento de texto para NLP. Los artículos anteriores son [parte 1](Preprocesamiento-de-texto-para-NLP-parte-1.html) y [parte 2](Preprocesamiento-de-texto-para-NLP-parte-2.html).\n",
    "\n",
    "En este nos vamos a focalizar en *embeddings* pre-entrenados. Los *embeddings* son un tema central en procesamiento del lenguaje y mucho se ha escrito al respecto. Acá hay algunos enlaces para introducrise en el tema\n",
    "* [The illustrated Word2Vec](http://jalammar.github.io/illustrated-word2vec)\n",
    "* [CS224n presentación *word vectors*](http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture01-wordvecs1.pdf)\n",
    "* [CS224n trabajo práctico *word vectors*](http://web.stanford.edu/class/cs224n/assignments/a1_preview/exploring_word_vectors.html)\n",
    "\n",
    "y acá dejamos algunos enlaces sobre cómo algunos *frameworks* abarcan el tema de este mismo artículo\n",
    "* [Keras](https://keras.io/examples/nlp/pretrained_word_embeddings)\n",
    "* [Gluon](https://gluon-nlp.mxnet.io/examples/word_embedding/word_embedding.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los embeddings son la primera capa en las redes neuronales que procesan texto. Mapean índices (a cada tóken le corresponde un índice, los índices corren de cero hasta `len(tókenes)`). Estamos mapeando enteros a vectores, a cada índice le corresponde un vector de palabra que codifica a la palabra. El mapeo se realiza por medio de una matriz que tiene tantas filas como índices y tantas columnas como la dimensión de los vectores. Esta dimensión es un hiperparámetro del modelo y básicamente significa la cantidad de atributos con la que representaremos a las palabras. Elegir una fila de la matriz, y a cada índice/tóken le corresponde una fila) estamos rebanando la matriz de modo de quedarnos con un vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el resto de las capas de una red neuronal que no ha sido entrenada los pesos de la capa de *embeddings* se inicializan al azar. O sea que al seleccionar un vector de palabra obtenemos un vector con componentes aleatorios. La idea central de los *embeddings* es que las palabras adquieren significado a partir de las palabras que la rodean. Una vez que la red neural ha sido entrenada y que los componentes de los vectores de palabras no son azarosos sino que han capturado en mayor o menor medida el significado de las palabras, la distancia entre los vectores ([similitud del coseno](https://es.wikipedia.org/wiki/Similitud_coseno) es una forma de calcular la distancia entre vectores) de palabras similares es más corta, es decir los *embeddings* están más cerca, que si cuando se consideran palabras con significados disímiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las primeras técnicas de transfencia de aprendizaje (*transfer learning*) fue utilizar *embeddings* pre-entrenados. La red neuronal con la que son entrenados y la que los utiliza con otros fines pueden tener arquitecturas bien distintas, comparten solamente los vectores de palabras, es decir la primera capa. Vimos que el armado del vocabulario es un asunto central y sería extraño que adoptemos el mismo vocabulario que la red que se utilizó para entrenar los *embeddings*; no es esto un problema mientras haya una intersección substancial entre el vocabulario que queremos utilizar y el que se utilizó para los *embeddings*, ya que nos estamos limitando a este último, posiblemente entrenado con un corpus general (Wikipedia) mientras que el vocabulario que necesitamos posiblemente pertenezca a un corpus particular. Todos los tókenes que no están en el vocabulario se denominan **fuera del vocabulario** (*out-of-vocabulary* u OOV) y requieren un tratamiento especial como ser ignorados/eliminados o mapeados a un tóken especial que codifique tókenes desconocidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los índices del vocabulario que crearemos tampoco será el mismo que los que se usaron para los vectores pre-entrenados. Por lo tanto la estrategia para obtener los pesos de la capa de vectores de palabra es la siguiente.\n",
    "\n",
    "1. Descargar los vectores pre-entrenados\n",
    "2. Obtener los vectores del vocabulario propio\n",
    "3. Ordenar los vectores según los índices propios\n",
    "4. Crear un tensor\n",
    "5. Inicializar los pesos de la capa de *embeddings*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargar los vectores pre-entrenados\n",
    "\n",
    "Los proyectos más conocidos son\n",
    "* Word2Vec\n",
    "* [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
    "* [fastText](https://fasttext.cc/docs/en/support.html)\n",
    "\n",
    "Vamos a usar fastText por tener vectores para idioma español y soporte para OOV. Primero instalamos el paquete de Python\n",
    "\n",
    "```bash\n",
    "pip install fasttext\n",
    "```\n",
    "\n",
    "y luego descargamos e inicializamos el modelo. Pesa unos 3,5 GB  así que la descarga puede demorar. La dimensión de los vectores de este modelo es 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "fasttext.util.download_model('es', if_exists='ignore')\n",
    "\n",
    "ft = fasttext.load_model('cc.es.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANTE**. Particularmente la carga de este modelo necesita de unos 12 GB de memoria RAM/swap, lo que me llevó a cerrar aplicaciones para liberar memoria. Para evitar pasar siempre por este paso, una vez que obtuve el tensor con los pesos necesarios lo salvé en un archivo; levantar este archivo es mucho más liviano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener los vectores del vocabulario\n",
    "\n",
    "Redefinimos ligeramente la clase `Vocab` que fuimos escribiendo en las partes anteriores. Lo nuevo es la propiedad `vocabulario`, que devuelve la lista de tókenes del vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# versión 5\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "class Vocab():\n",
    "    # ningún cambio aquí\n",
    "    @property\n",
    "    def índice_relleno(self):\n",
    "        return self.mapeo.get(self.tóken_relleno)\n",
    "    \n",
    "    # ningún cambio aquí\n",
    "    def __init__(self, tóken_desconocido='<unk>', tóken_relleno='<pad>', frecuencia_mínima=0.0, frecuencia_máxima=1.0,\n",
    "                 longitud_mínima=1, longitud_máxima=np.inf, stop_words=[], límite_vocabulario=None):\n",
    "        \n",
    "        self.tóken_desconocido = tóken_desconocido\n",
    "        self.tóken_relleno = tóken_relleno\n",
    "        self.frecuencia_mínima = frecuencia_mínima\n",
    "        self.frecuencia_máxima = frecuencia_máxima\n",
    "        self.longitud_mínima = longitud_mínima\n",
    "        self.longitud_máxima = longitud_máxima\n",
    "        self.stop_words = stop_words\n",
    "        self.límite_vocabulario = límite_vocabulario\n",
    "    \n",
    "    # ningún cambio aquí\n",
    "    def reducir_vocabulario(self, lote):\n",
    "        contador_absoluto = Counter(chain(*lote))\n",
    "        \n",
    "        contador_documentos = Counter()\n",
    "        \n",
    "        for doc in lote:\n",
    "            contador_documentos.update(set(doc))\n",
    "        \n",
    "        # frecuencia mínima\n",
    "        if isinstance(self.frecuencia_mínima, int): # frecuencia de tóken\n",
    "            vocabulario_mín = [tóken for tóken, frecuencia in contador_absoluto.most_common() if frecuencia >= self.frecuencia_mínima]\n",
    "        else: # frecuencia de documento\n",
    "            vocabulario_mín = [tóken for tóken, frecuencia in contador_documentos.most_common() if frecuencia/len(lote) >= self.frecuencia_mínima]\n",
    "        \n",
    "        # frecuencia máxima\n",
    "        if isinstance(self.frecuencia_máxima, int): # frecuencia de tóken\n",
    "            vocabulario_máx = [tóken for tóken, frecuencia in contador_absoluto.most_common() if self.frecuencia_máxima >= frecuencia]\n",
    "        else: # frecuencia de documento\n",
    "            vocabulario_máx = [tóken for tóken, frecuencia in contador_documentos.most_common() if self.frecuencia_máxima >= frecuencia/len(lote)]\n",
    "\n",
    "        # intersección de vocabulario_mín y vocabulario_máx preservando el órden\n",
    "        vocabulario = [tóken for tóken in vocabulario_mín if tóken in vocabulario_máx]\n",
    "\n",
    "        # longitud\n",
    "        vocabulario = [tóken for tóken in vocabulario if self.longitud_máxima >= len(tóken) >= self.longitud_mínima]\n",
    "        \n",
    "        # stop words\n",
    "        vocabulario = [tóken for tóken in vocabulario if tóken not in self.stop_words]\n",
    "        \n",
    "        # límite\n",
    "        vocabulario = vocabulario[:self.límite_vocabulario]\n",
    "        \n",
    "        return vocabulario\n",
    "        \n",
    "    def fit(self, lote):\n",
    "        vocabulario = []\n",
    "        \n",
    "        if self.tóken_relleno:\n",
    "            vocabulario.append(self.tóken_relleno)\n",
    "        \n",
    "        if self.tóken_desconocido:\n",
    "            vocabulario.append(self.tóken_desconocido)\n",
    "        \n",
    "        vocabulario += self.reducir_vocabulario(lote)\n",
    "        \n",
    "        self.mapeo = {tóken: índice for índice, tóken in enumerate(vocabulario)}\n",
    "\n",
    "        return self\n",
    "    \n",
    "    # ningún cambio aquí\n",
    "    def transform(self, lote):\n",
    "        if self.tóken_desconocido: # reemplazar\n",
    "            return [[tóken if tóken in self.mapeo else self.tóken_desconocido for tóken in doc] for doc in lote]\n",
    "        else: # ignorar\n",
    "            return [[tóken for tóken in doc if tóken in self.mapeo] for doc in lote]\n",
    "    \n",
    "    # ningún cambio aquí\n",
    "    def tókenes_a_índices(self, lote):\n",
    "        lote = self.transform(lote)\n",
    "        \n",
    "        return [[self.mapeo[tóken] for tóken in doc] for doc in lote]\n",
    "    \n",
    "    # ningún cambio aquí\n",
    "    def índices_a_tókenes(self, lote):\n",
    "        mapeo_inverso = list(self.mapeo.keys())\n",
    "        \n",
    "        return [[mapeo_inverso[índice] for índice in doc] for doc in lote]\n",
    "    \n",
    "    # ningún cambio aquí\n",
    "    def __len__(self):\n",
    "        return len(self.mapeo)\n",
    "    \n",
    "    @property\n",
    "    def vocabulario(self):\n",
    "        return list(v.mapeo.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el vocabulario como lo hicimos anteriormente (parte 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train.csv', sep='|')\n",
    "\n",
    "# hacemos una tokenización muy simple\n",
    "def tokenizar(texto):\n",
    "    return texto.split()\n",
    "\n",
    "train_docs = [tokenizar(doc) for doc in df['Pregunta'].values]\n",
    "\n",
    "v = Vocab().fit(train_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde Python 3.7 está garantizado que el orden del diccionario es el orden de inserción. Por lo tanto el órden de la lista `v.vocabulario` coincide con el del diccionario `v.mapeo` (ver implementación de `Vocab`). Tener claro el órden / los índices de los tókenes es importante porque crearemos un tensor de *embeddings* al cuál accederemos mediante índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '<unk>', 'de', 'el', 'la', 'tarjeta', 'que', 'para', 'un', 'me']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.vocabulario[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, el *embedding* del tóken `tarjeta` será `embeddings[5]` ya que el tóken está en el quinto lugar del vocabulario (recordar que empezamos a contar por cero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La interfaz de fastText para obtener un vector a partir de un tóken es como la de un diccionario. Así luce un *embedding* de dimensión 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06298134, -0.03280621,  0.03053921, -0.14426479, -0.04330583,\n",
       "        0.02782611,  0.04671088,  0.01322352, -0.00091936, -0.02005653,\n",
       "       -0.08679762, -0.00335382, -0.04299804,  0.03553167, -0.07989401,\n",
       "        0.00514562,  0.06741733, -0.01824431, -0.0627635 , -0.03652998,\n",
       "       -0.02327815, -0.06624147,  0.00762858,  0.04288524, -0.02111394,\n",
       "       -0.02724549,  0.01001478, -0.0437385 , -0.07554701,  0.00330107,\n",
       "       -0.00436452, -0.03166814, -0.02237143, -0.00398921, -0.00873911,\n",
       "        0.01801448,  0.06549975,  0.02997639,  0.04104616,  0.08769971,\n",
       "       -0.06594162, -0.01973427,  0.03386661, -0.05415446, -0.0547767 ,\n",
       "       -0.00098864, -0.00864553,  0.05127762,  0.02343957, -0.00937056,\n",
       "       -0.03792336,  0.06513872,  0.03453366,  0.00376538,  0.00911847,\n",
       "        0.03639029, -0.04959448, -0.10815199,  0.0189229 , -0.00545404,\n",
       "       -0.0441896 ,  0.05246361, -0.08793913,  0.01742068,  0.07848521,\n",
       "        0.00829239,  0.00512537, -0.00187416,  0.06793492, -0.0205775 ,\n",
       "        0.09385861,  0.06492148,  0.08256735, -0.01685029,  0.04042866,\n",
       "       -0.03420147, -0.01297663, -0.03008673,  0.06171214, -0.0073834 ,\n",
       "       -0.00952853, -0.07957197,  0.05753422, -0.00230803,  0.01646664,\n",
       "        0.00405738,  0.01874345, -0.01656639,  0.03835326,  0.00671893,\n",
       "        0.03538686, -0.05837374,  0.00655341, -0.06613984, -0.00893264,\n",
       "        0.01970789, -0.02059824, -0.01957787,  0.04642227, -0.03362621,\n",
       "       -0.03894996, -0.03437151, -0.0639662 , -0.00890221, -0.02950617,\n",
       "        0.030174  ,  0.00092385,  0.08426531, -0.00274815,  0.00948968,\n",
       "        0.04102866,  0.01430673,  0.01487885,  0.0998308 , -0.0284079 ,\n",
       "       -0.00470919,  0.03808989,  0.08536439,  0.03592137,  0.07948075,\n",
       "        0.0172466 , -0.07252405, -0.0107453 ,  0.0275656 ,  0.02603439,\n",
       "        0.01865727, -0.10967878,  0.04329263, -0.03052348,  0.01704779,\n",
       "       -0.05844689,  0.06367239,  0.00445418,  0.1319068 ,  0.02953896,\n",
       "        0.02432506,  0.04764185,  0.04224063, -0.05673009, -0.00072847,\n",
       "       -0.01646314,  0.0195642 ,  0.02678232, -0.02039818,  0.01072512,\n",
       "        0.03165798,  0.02296546,  0.03048908,  0.00605224,  0.03494508,\n",
       "       -0.03987421,  0.10772546,  0.05239586, -0.05665122, -0.04541425,\n",
       "       -0.03411638,  0.00866744, -0.10566777, -0.06131719, -0.0434983 ,\n",
       "        0.07758161, -0.05220485,  0.03249336, -0.12057097,  0.05518946,\n",
       "       -0.00267152, -0.0791545 ,  0.00928127, -0.03528287, -0.07231892,\n",
       "       -0.00943873,  0.02749985, -0.02224496,  0.001105  , -0.04838763,\n",
       "        0.02414943,  0.00739839,  0.03333126,  0.0515946 , -0.0163026 ,\n",
       "        0.06550607, -0.01794759,  0.07309239,  0.01166206, -0.01817643,\n",
       "        0.00392749,  0.00703375,  0.03426434,  0.02729288, -0.00475265,\n",
       "        0.01720353,  0.04551698, -0.02496281, -0.06664832, -0.02822311,\n",
       "        0.03184071, -0.02069683, -0.03815257,  0.02659006,  0.18702458,\n",
       "       -0.0493904 ,  0.02795539, -0.06647408,  0.02131662,  0.01693988,\n",
       "        0.04659843, -0.04887157, -0.09692122, -0.07950865,  0.06913692,\n",
       "       -0.0173317 ,  0.00877939, -0.06175148,  0.05520935,  0.04833567,\n",
       "        0.00859433,  0.0169889 , -0.02598299,  0.0434835 , -0.03762854,\n",
       "       -0.02821014, -0.00132759, -0.06334166,  0.00318673,  0.01190044,\n",
       "       -0.02857058, -0.01841859, -0.00682279,  0.00447517, -0.01528993,\n",
       "       -0.07283813,  0.00650864,  0.01897584, -0.00431945, -0.02006911,\n",
       "        0.07013839, -0.02700875,  0.04124613, -0.01243533, -0.04903939,\n",
       "       -0.01877775,  0.0053995 , -0.00930875, -0.03993747,  0.01549599,\n",
       "       -0.01568508, -0.05651587,  0.06928204,  0.01355214, -0.0159476 ,\n",
       "        0.04126405,  0.04020314,  0.10078269,  0.02648922,  0.06171743,\n",
       "       -0.01357437,  0.0018341 , -0.00616703,  0.04361626,  0.00650506,\n",
       "        0.05089275, -0.00275116,  0.02991083, -0.11814439, -0.01024311,\n",
       "        0.07333191, -0.02508869,  0.01686102,  0.01045217, -0.07310145,\n",
       "       -0.01285514,  0.09339073, -0.06714858, -0.09901267,  0.0068216 ,\n",
       "        0.03572355, -0.03935919,  0.03302537,  0.02549176,  0.0144202 ,\n",
       "       -0.02991694, -0.01354563, -0.00787938,  0.03613688,  0.05657197,\n",
       "       -0.00474709, -0.02503674, -0.0273344 ,  0.05442371, -0.01384753,\n",
       "        0.00932324, -0.04490621, -0.03971119,  0.02634538, -0.02593908,\n",
       "        0.04915658,  0.04001555, -0.1161194 , -0.08524479, -0.04748566],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft['tarjeta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la distancia entre *embeddings* de tókenes similares, por ejemplo debido a un error ortográfico, y la de tókenes disímiles, de diferente significado.\n",
    "\n",
    "Para ello utilizaré la similitud del coseno, una fórmula trigonométrica que en la definición de `scipy` es igual a cero si ambos vectores apuntan a un mismo lugar; cualquier ángulo existente entre los vectores, arrojaría un valor mayor a cero.\n",
    "\n",
    "Los índices son cateorías que nada dicen de la relación entre las palabras pero los vectores sí.\n",
    "\n",
    "* https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "distance.cosine(ft['tarjeta'], ft['tarjeta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error ortográfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18840116262435913"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(ft['tarjeta'], ft['targeta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra palabra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6775485575199127"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(ft['tarjeta'], ft['saldo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguente función servirá para\n",
    "1. obtener los vectores de cada uno de los tókenes del vocabulario,\n",
    "2. en el orden de los índices del vocabulario (es importante mantener este orden),\n",
    "3. convertirlos en tensores de PyTorch (`map` aplica la función `torch.tensor` a cada uno de los vectores),\n",
    "4. `list` convierte el mapeo es una lista, ya que `map` es *lazy*, no acciona hasta que se lo piden y convertirlo en lista es una manera de pedirlo,\n",
    "5. `torch.stack` apila los tensores de la lista (cada uno tiene dimensión 300 y la lista tiene largo $N$, el tamaño del vocabulario) en un tensor bidimensional de $N \\times 300$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# versión 1\n",
    "def obtener_embeddings(tókenes, fastText):\n",
    "    \n",
    "    embeddings = [fastText[tóken] for tóken in tókenes]\n",
    "\n",
    "    return torch.stack( list( map(torch.tensor, embeddings) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0503, -0.0404,  0.0759,  ...,  0.0252, -0.0356, -0.0142],\n",
       "        [ 0.0093,  0.0350,  0.0453,  ..., -0.0111, -0.0165, -0.0326],\n",
       "        [ 0.0547,  0.0112,  0.1910,  ...,  0.0066, -0.0021, -0.0230],\n",
       "        ...,\n",
       "        [-0.0278, -0.0258,  0.0990,  ...,  0.0018, -0.0074, -0.0465],\n",
       "        [ 0.0149, -0.0274,  0.0268,  ...,  0.0571,  0.0106, -0.0065],\n",
       "        [-0.0097,  0.0221, -0.0038,  ..., -0.0042,  0.0152,  0.0462]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = obtener_embeddings(v.vocabulario, ft)\n",
    "\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces ahora podemos salvarlos para no tener que volver a generarlos, obviando así cargar el modelo de fastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings, 'vectores.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos cargarlos más adelante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.load('vectores.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: bolsa de palabras\n",
    "\n",
    "Hay una forma simple y efectiva de obtener la representación de un documento, si bien existen otras que son mejores. Los vectores son representaciones de tókenes, los documentos son conjuntos de tókenes, calcular la suma, el promedio o el máximo de los vectores del conjunto nos da un vector que es la representación del documento. Como esta agregación no tiene en cuenta el orden de los tókenes en el documento se llama **bolsa de palabras**, o en inglés *bag of words*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 300])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cambio_cien = obtener_embeddings(['señor', 'tiene', 'cambio', 'de', 'cien'], ft)\n",
    "\n",
    "cambio_cien.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos la agregación es en sentido de las columnas, cada columna o dimensión del *embedding* es un atributo o *feature* del tóken, queremos obtener los atributos para el documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cambio_cien = torch.mean(cambio_cien, dim=0)\n",
    "\n",
    "cambio_cien.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representación de una variante del documento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambio_mil = obtener_embeddings(['señor', 'tiene', 'cambio', 'de', 'mil'], ft)\n",
    "cambio_mil = torch.mean(cambio_mil, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representación de un documento bien diferente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "extravío = obtener_embeddings(['extravié', 'mi', 'tarjeta', 'de', 'débito', 'anoche'], ft)\n",
    "extravío = torch.mean(extravío, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos las distancias entre los documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08124548196792603"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(cambio_cien, cambio_mil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39364296197891235"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(cambio_cien, extravío)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que `señor tiene cambio de cien` está más cerca de `señor tiene cambio de mil` que de `extravié mi tarjeta de débito anoche`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la parte 2 hube mencionado a `nn.EmbeddingBag` sin contar su finalidad; es un módulo de PyTorch que hace exactamento esto: recibe un tensor con índices de tókenes de documentos, reemplaza a los índices por vectores y los agrega en un vector por documento, usando una función que puede ser `mean`, `max`, `sum`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializar los pesos de la capa de *embeddings*\n",
    "\n",
    "El método `copy_` carga el tensor de los pesos en el módulo de *embeddings*. Para que la carga funcione las dimensiones del tensor de pesos debe ser exactamente igual a las de la capa. Inicializamosla con cantidad de filas igual al largo del vocabulario y cantidad de columnas igual al tamaño de los vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingBag(8116, 300, mode=mean)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capa = nn.EmbeddingBag(len(v), ft.get_dimension(), mode='mean')\n",
    "capa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequeamos las dimensiones del tensor de pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8116, 300])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al inicializar la capa, sus pesos se inicializan con valores al azar. Es con el entrenamiento que adquieren valores significativos para red neuronal. Los *embeddings* pre-entrenados sirven justamente para comenzar con valores con sentido, lo que acorta los tiempos de aprendizaje de la red en general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0503, -0.0404,  0.0759,  ...,  0.0252, -0.0356, -0.0142],\n",
       "        [ 0.0093,  0.0350,  0.0453,  ..., -0.0111, -0.0165, -0.0326],\n",
       "        [ 0.0547,  0.0112,  0.1910,  ...,  0.0066, -0.0021, -0.0230],\n",
       "        ...,\n",
       "        [-0.0278, -0.0258,  0.0990,  ...,  0.0018, -0.0074, -0.0465],\n",
       "        [ 0.0149, -0.0274,  0.0268,  ...,  0.0571,  0.0106, -0.0065],\n",
       "        [-0.0097,  0.0221, -0.0038,  ..., -0.0042,  0.0152,  0.0462]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capa.weight.data.copy_(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 119, 142, 2, 1], [1, 119, 142, 2, 1311], [2268, 11, 5, 2, 149, 1443]]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "índices = v.tókenes_a_índices([\n",
    "    ['señor', 'tiene', 'cambio', 'de', 'cien'],\n",
    "    ['señor', 'tiene', 'cambio', 'de', 'mil'],\n",
    "    ['extravié', 'mi', 'tarjeta', 'de', 'débito', 'anoche'],\n",
    "])\n",
    "\n",
    "índices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por cómo creamos el vocabulario y por cómo está definida la clase `Vocab`, el tóken `<unk>` de tóken desconocido o fuera del vocabulario tiene asignado el índice `1`; esto será relevante más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que a este módulo le gusta que los documentos sean contiguos (un único documento) y que por otro lado le informemos en qué posiciones de ese documento contiguo comienza cada uno de los documentos.\n",
    "\n",
    "Veamos el largo de cada uno de los documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 6]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len, índices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer documento siempre comienza en la posición `0`, el segundo lo hace `5` tókenes/índices después, y el tercero en 5 luego del segundo, o sea en la posición `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "posiciones = torch.tensor([0, 5, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convertimos a los documentos en un documento único y además en un tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "índices = torch.tensor([\n",
    "    1, 119, 142, 2, 1, 1, 119, 142, 2, 1311, 2268, 11, 5, 2, 149, 1443\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de estos procesamientos la capa ejecuta las mismas operaciones que realizamos manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 300])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectores = capa(índices, posiciones)\n",
    "\n",
    "vectores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que podemos verificar calculando la distancia entre `señor tiene cambio de cien` está más cerca de `señor tiene cambio de mil`, que manualmente dio $0.081$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1781657338142395"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(vectores[0].detach().numpy(), vectores[1].detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Y no se cumplió**. 😵\n",
    "\n",
    "La explicación está en las palabras fuera del vocabulario. Los *embeddings* pre-entrenados no suelen venir con pesos para tókenes especiales como `<unk>` y al hacer `ft['<unk>']`, fastText que está preparado para generar vectores para tókenes con los cuales no fue entrenado, devuelve un vector con pesos sin sentido. Es decir, fastText es muy útil para obtener vectores aproximados cuando le preguntamos por un tóken que no conoce pero que es parecido a otros que sí, sin embargo `<unk>` no se a parece a ningún otro. Nota: Word2Vec y GloVe no tienen soporte para tókenes fuera del vocabulario (OOV), en el caso de `<unk>` no hubieran devuelto ningún valor.\n",
    "\n",
    "¿Qué podríamos haber hecho?\n",
    "* Si contamos con soporte para OOV (fastText), no usar el tóken `<unk>` ya que no es necesario. Para ello deberíamos haber creado el vocabulario inicilizando la clase `Vocab` con el argumento `tóken_desconocido=None`.\n",
    "* Si no hay soporte para OOV, salvo que el modelo especifique que cuenta con un vector para el tóken especial *desconocido* (y que no necesariamente se simbolizará con `<unk>`), no usar el tóken `<unk>` ya que no es posible.\n",
    "* Entrenar vectores desde cero. Al existir `<unk>`, este adquire pesos con el sentido propuesto. No era la idea.\n",
    "* Crear un vector a partir de los existentes, según está expresado en esta [respuesta de StackOverflow](https://stackoverflow.com/questions/49239941/what-is-unk-in-the-pretrained-glove-vector-files-e-g-glove-6b-50d-txt).\n",
    "\n",
    "### Creando un vector desconocido\n",
    "\n",
    "La respuesta de StackOverflow del último punto sugiere que el **vector promedio de todos los vectores** o, de al menos los que se van a usar, conforman un buen vector desconocido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk = embeddings.mean(dim=0)\n",
    "\n",
    "unk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando un vector de relleno\n",
    "\n",
    "Otro tóken especial que consideramos es el relleno, `<pad>`, que sirve para completar los espacios en documentos de distinto largo cuando los queremos agrupar en un tensor. Normalmente los pesos para este vector son todos ceros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = torch.zeros(ft.get_dimension())\n",
    "\n",
    "pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incluyendo los nuevos cambios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# versión 2\n",
    "def obtener_embeddings(tókenes, fastText, tóken_desconocido='<unk>', tóken_relleno='<pad>'):\n",
    "    \n",
    "    embeddings = [fastText[tóken] for tóken in tókenes if tóken not in (tóken_desconocido, tóken_relleno)]\n",
    "    embeddings = torch.stack( list( map(torch.tensor, embeddings) ) )\n",
    "    \n",
    "    if tóken_desconocido:\n",
    "        unk = embeddings.mean(dim=0, keepdim=True)\n",
    "        embeddings = torch.cat([unk, embeddings])\n",
    "    \n",
    "    if tóken_relleno:\n",
    "        pad = torch.zeros(1, fastText.get_dimension())\n",
    "        embeddings = torch.cat([pad, embeddings])\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0008, -0.0102,  0.0071,  ..., -0.0066,  0.0097, -0.0056],\n",
       "        [ 0.0547,  0.0112,  0.1910,  ...,  0.0066, -0.0021, -0.0230],\n",
       "        ...,\n",
       "        [-0.0278, -0.0258,  0.0990,  ...,  0.0018, -0.0074, -0.0465],\n",
       "        [ 0.0149, -0.0274,  0.0268,  ...,  0.0571,  0.0106, -0.0065],\n",
       "        [-0.0097,  0.0221, -0.0038,  ..., -0.0042,  0.0152,  0.0462]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = obtener_embeddings(v.vocabulario, ft)\n",
    "\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializar los pesos en un modelo\n",
    "\n",
    "Respecto del modelo de la parte 2, la diferencia está en el método `init_weights` que carga el tensor de los pesos en la capa de *embeddings* y que es llamado durante la inicialización del modelo. Recordemos: para que la carga funcione (`copy_`) las dimensiones del tensor de pesos debe ser exactamente igual a las de la capa de *embedding*.\n",
    "\n",
    "Además **congelamos los pesos** (`requires_grad = False`) para que no cambien durante el entrenamiento. Lo que se aconseja es entrenar el resto de las capas hasta que la función de pérdida se estabilice; dejar libres a los pesos de la capa de *embeddings* cuando el resto de la red tiene pesos con valores aleatorios hará que los *embeddings* varíen significativamente durante el aprendizaje y pierdan sentido. Suele ser útil descongelar los pesos una vez que el modelo ha alcanzado cierto nivel de aprendizaje para efectuar un aprendizaje fino, en el que los *embeddings* se adaptarán al problema en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DIM_EMBEDDINGS = 8\n",
    "\n",
    "class ClasificadorBolsa(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False, mode='max')\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "\n",
    "        # inicializamos los pesos\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.embedding.weight.data.copy_(embeddings)\n",
    "        self.embedding.weight.data.requires_grad = False\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Embedding\n",
    "\n",
    "Hemos visto con algo de detalle el módulo de PyTorch `nn.EmbeddingBag`, una capa de doble acción: convierte índices en vectores y calcula un vector agregado, una forma simple de obtener una representación de un documento, aunque no la más efectiva de todas. Para lograr mejores representaciones encontramos en uso modelos más complejos. La primera capa de modelos que usan capas LSTM o Transformer es una `nn.Embedding`, que a diferencia de la mencionada anteriormente es de simple acción: convierte índices en vectores y ya.\n",
    "\n",
    "Quiero ilustrar brevemente cómo son la entrada y la salida de esta capa, ya que son bien diferentes a las de `nn.EmbeddingBag`. La inicialización sin embargo, es similar. El tensor de los pesos tendrá las dimensiones de tamaño del vocabulario por la dimensión (valga la redundancia) de los *embeddings*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "capa = nn.Embedding(len(v), ft.get_dimension(), padding_idx=v.índice_relleno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferentemente, como esta capa requiere el uso del tóken de relleno, podemos especificar el índice del tóken para que la capa inicialice sus pesos al azar excepto los de este vector, que será inicializado en cero. Si lo deseamos, podemos utilizar vectores pre-entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "capa.weight.data.copy_(embeddings)\n",
    "capa.weight.data.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora armaremos un lote de documentos y lo convertiremos en un tensor. Para poder hacer esto último es fundamental que los documentos tengan el mismo largo (que será igual al del documento más largo), así que nos valdremos del tóken de relleno para lograrlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "índices = v.tókenes_a_índices([\n",
    "    ['señor', 'tiene', 'cambio', 'de', 'cien', '<pad>'],\n",
    "    ['señor', 'tiene', 'cambio', 'de', 'mil', '<pad>'],\n",
    "    ['extravié', 'mi', 'tarjeta', 'de', 'débito', 'anoche'],\n",
    "])\n",
    "\n",
    "índices = torch.tensor(índices)\n",
    "\n",
    "índices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un tensor bidimensional, la dimensión 0 (filas) es la cantidad de documentos del lote, la dimensión 1 (columnas) es el tamaño de los documentos.\n",
    "\n",
    "Así luce el tensor de índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,  119,  142,    2,    1,    0],\n",
       "        [   1,  119,  142,    2, 1311,    0],\n",
       "        [2268,   11,    5,    2,  149, 1443]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "índices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo hacemos pasar por la capa de *embeddings*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 300])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectores = capa(índices)\n",
    "\n",
    "vectores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que la capa anadió una nueva dimensión, ahora tenemos un tensor tridimensional. Reemplazó cada índice (un escalar) por su vector correspondiente de largo 300. La dimensión 2 (profundidad) siempre corresponderá al tamaño del *embedding*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí termina la serie de artículos de pre-procesamiento de texto. Gracias por haber llegado hasta el fin."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
